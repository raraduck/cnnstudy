{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a466da40-f02f-4f9d-a244-bb58066f10fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "fashion_mnist_train = FashionMNIST(\"./data/FashionMNIST\",\n",
    "                                   train=True, download=True,\n",
    "                                   transform=transforms.ToTensor())\n",
    "fashion_mnist_test = FashionMNIST(\"./data/FashionMNIST\",\n",
    "                                   train=False, download=True,\n",
    "                                   transform=transforms.ToTensor())\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "batch_size = 128\n",
    "fashion_train_loader = DataLoader(fashion_mnist_train,\n",
    "                          batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "fashion_test_laoder = DataLoader(fashion_mnist_test,\n",
    "                         batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388d2d32-a0eb-42b2-b175-cc523ac03b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./ch5_CNN/data/MNIST\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./ch5_CNN/data/FashionMNIST\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from ch5_CNN.data.load_data import load_mnist_torchvision, load_fashion_mnist_torchvision\n",
    "\n",
    "mnist_train_loader, mnist_test_loader = load_mnist_torchvision(\n",
    "    target_path=\"./data/MNIST\",\n",
    "    batch_size=256)\n",
    "fashion_train_loader, fashion_test_loader = load_fashion_mnist_torchvision(\n",
    "    target_path=\"./data/FashionMNIST\",\n",
    "    batch_size=256)\n",
    "\n",
    "print(mnist_train_loader.dataset)\n",
    "print(fashion_train_loader.dataset)\n",
    "print(mnist_train_loader.dataset[0][0].shape)\n",
    "print(fashion_train_loader.dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53f77025-41b5-4c9b-aca1-fccf12b759f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.752349043992456 0.7913494925213675 0.9281350374221802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.18584598664817892 0.9446948450854701 0.9590011239051819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.11567081928317127 0.9652110042735043 0.9724059104919434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.08924105255005185 0.9734074519230769 0.9774305820465088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.07342666876002699 0.977981436965812 0.9814870953559875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.062395951254972826 0.9814870459401709 0.9828726649284363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.055145629973434585 0.9834234775641025 0.9852932095527649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.04959662773850266 0.9846587873931624 0.9877638220787048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.04396180249750614 0.9867955395299145 0.9885150194168091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 40.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.040673955039884656 0.9877136752136753 0.9894832372665405\n"
     ]
    }
   ],
   "source": [
    "from ch5_CNN.train.run_training import training_loop\n",
    "from torch import nn, optim\n",
    "from ch5_CNN.models.load_models import MyCNN\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=256\n",
    "model = MyCNN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(10, optimizer, model, loss_fn, mnist_train_loader, mnist_test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea16b33-babb-451d-8dea-e89f8056d4e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0348, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array(2.305925, dtype=float32),\n",
       " array(0.24283533, dtype=float32),\n",
       " array(0.16627231, dtype=float32),\n",
       " array(0.17016415, dtype=float32),\n",
       " array(0.12773502, dtype=float32),\n",
       " array(0.06039842, dtype=float32),\n",
       " array(0.09992194, dtype=float32),\n",
       " array(0.05473701, dtype=float32),\n",
       " array(0.02720312, dtype=float32),\n",
       " array(0.03477221, dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ch4_dataloader.train.run_training import training_loop\n",
    "from torch import nn, optim\n",
    "from ch4_dataloader.models.load_models import MyCNN\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=256\n",
    "model = MyCNN(batch_size=batch_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(10, optimizer, model, loss_fn, mnist_train_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b4f59-ab9e-40a4-a483-9095f52408e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
