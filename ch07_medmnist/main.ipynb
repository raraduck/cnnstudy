{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7866bd-8c16-4bbb-81de-4e6140d2981d",
   "metadata": {},
   "source": [
    "# loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb126e-99d2-43bb-a1f0-e50c6765824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CelebA, CIFAR10, CIFAR100\n",
    "import medmnist\n",
    "from medmnist import ChestMNIST, PneumoniaMNIST\n",
    "from torchvision import transforms\n",
    "from _utils.load_utils import display_from_batch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# params: batch_size\n",
    "batch_size = 256\n",
    "\n",
    "# train = FashionMNIST(\"./_data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# test = FashionMNIST(\"./_data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# classnames = {\n",
    "#     0:'T-shirt/top',\n",
    "#     1:'Trouser',\n",
    "#     2:'Pullover',\n",
    "#     3:'Dress',\n",
    "#     4:'Coat',\n",
    "#     5:'Sandal',\n",
    "#     6:'Shirt',\n",
    "#     7:'Sneaker',\n",
    "#     8:'Bag',\n",
    "#     9:'Ankle boot',\n",
    "# }\n",
    "# train = PneumoniaMNIST(root=\"./_data\", split=\"train\", download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# test = PneumoniaMNIST(root=\"./_data\", split=\"test\", download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# classnames={0: 'normal', 1: 'pneumonia'}\n",
    "\n",
    "# train = ChestMNIST(root=\"./_data\", split=\"train\", download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# test = ChestMNIST(root=\"./_data\", split=\"test\", download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# classnames={\n",
    "#     '0': 'atelectasis', \n",
    "#     '1': 'cardiomegaly', \n",
    "#     '2': 'effusion', \n",
    "#     '3': 'infiltration', \n",
    "#     '4': 'mass', \n",
    "#     '5': 'nodule', \n",
    "#     '6': 'pneumonia', \n",
    "#     '7': 'pneumothorax', \n",
    "#     '8': 'consolidation', \n",
    "#     '9': 'edema', \n",
    "#     '10': 'emphysema', \n",
    "#     '11': 'fibrosis', \n",
    "#     '12': 'pleural', \n",
    "#     '13': 'hernia'\n",
    "# }\n",
    "\n",
    "\n",
    "# train = CelebA(root='./_data', split='train', transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
    "# test = CelebA(root='./_data', split='test', transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
    "\n",
    "# train = CIFAR10(root=\"./_data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# test = CIFAR10(root=\"./_data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# classnames={\n",
    "#     '0': 'airplane', \n",
    "#     '1': 'automobile', \n",
    "#     '2': 'bird', \n",
    "#     '3': 'cat', \n",
    "#     '4': 'deer', \n",
    "#     '5': 'dog', \n",
    "#     '6': 'frog', \n",
    "#     '7': 'horse', \n",
    "#     '8': 'ship', \n",
    "#     '9': 'truck', \n",
    "# }\n",
    "\n",
    "train = CIFAR100(root=\"./_data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = CIFAR100(root=\"./_data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# classnames={\n",
    "#     '0': 'airplane', \n",
    "#     '1': 'automobile', \n",
    "#     '2': 'bird', \n",
    "#     '3': 'cat', \n",
    "#     '4': 'deer', \n",
    "#     '5': 'dog', \n",
    "#     '6': 'frog', \n",
    "#     '7': 'horse', \n",
    "#     '8': 'ship', \n",
    "#     '9': 'truck', \n",
    "# }\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79f415-8672-4046-9b6d-86ca2b5ea183",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad792d-1279-4b1d-b1a3-bcf2228d862a",
   "metadata": {},
   "source": [
    "# _utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92e1d5-cfb2-49d0-8914-b066834fd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5be8f-ad94-4a00-81a4-0408dd07e77f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batch = next(train_iter)\n",
    "# params: batch, classname, nrows, ncols\n",
    "print(train_batch[1][:4])\n",
    "print(train_batch[0].shape)\n",
    "# print(train_batch[1].squeeze(1))\n",
    "# print(train_batch[1].squeeze(1).to(torch.long))\n",
    "# print(train_batch[1].squeeze(1).to(torch.long).dtype)\n",
    "display_from_batch(train_batch, 2, 4, classnames)\n",
    "\n",
    "# return none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c2e7c-ba5c-475f-b1bd-92913553922a",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838c802-b3dd-452f-b4ed-9273b81274da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, channels, height, width, out_features):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, 16, kernel_size=5, padding=0)\n",
    "        self.act1 = nn.ReLU()\n",
    "        h = (height - 4)\n",
    "        w = (width - 4)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, padding=0)\n",
    "        self.act2 = nn.ReLU()\n",
    "        h = (h - 4)\n",
    "        w = (w - 4)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        h = h / 2\n",
    "        w = w / 2\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, padding=0)\n",
    "        self.act3 = nn.ReLU()\n",
    "        h = (h - 4)\n",
    "        w = (w - 4)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        h = h / 2\n",
    "        w = w / 2\n",
    "        # 3x3 이미지가 됨\n",
    "        self.fc4 = nn.Linear(64 * int(h) * int(w), 100)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.fc5 = nn.Linear(100, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # 모듈화 필요>>>\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], -1)\n",
    "        # <<<모듈화 필요\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40c296-8131-4a15-a0d6-ba75b960892e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MyCNN(channels=3, height=32, width=32, out_features=10)\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list\n",
    "print('MyCNN: ', sum(numel_list), numel_list)\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(1,3,32,32), device='cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c4285-f5b2-4d66-88f9-1904e4cc7acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, C, H, W, num_classes = 10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.n_chans1 = 64\n",
    "        self.conv1 = nn.Conv2d(C, self.n_chans1, kernel_size=3)\n",
    "        self.act1 = nn.ReLU()\n",
    "        c = self.n_chans1\n",
    "        h = H - 2\n",
    "        w = W - 2\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        h = h // 2\n",
    "        w = w // 2\n",
    "        self.conv2 = nn.Conv2d(c, c * 3, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        c = c * 3\n",
    "        h = h // 2\n",
    "        w = w // 2\n",
    "        self.conv3 = nn.Conv2d(c, c * 2, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "        c = c * 2\n",
    "        self.conv4 = nn.Conv2d(c, c * 2 // 3, kernel_size=3, padding=1)\n",
    "        self.act4 = nn.ReLU()\n",
    "        c = c * 2 // 3\n",
    "        self.conv5 = nn.Conv2d(c, c, kernel_size=1)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.pool5 = nn.MaxPool2d(2)\n",
    "        h = h // 2\n",
    "        w = w // 2\n",
    "        self.dropout6 = nn.Dropout2d(p=0.5)\n",
    "        self.fc6 = nn.Linear(c * h * w, 1024)\n",
    "        self.act6 = nn.ReLU()\n",
    "        self.dropout7 = nn.Dropout2d(p=0.5)\n",
    "        self.fc7 = nn.Linear(1024, 512)\n",
    "        self.act7 = nn.ReLU()\n",
    "        self.fc8 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.act5(x)\n",
    "        x = self.pool5(x)\n",
    "        \n",
    "        # 모듈화 필요>>>\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], -1)\n",
    "        # <<<모듈화 필요\n",
    "        \n",
    "        x = self.dropout6(x)\n",
    "        x = self.fc6(x)\n",
    "        x = self.act6(x)\n",
    "        \n",
    "        x = self.dropout7(x)\n",
    "        x = self.fc7(x)\n",
    "        x = self.act7(x)\n",
    "        \n",
    "        x = self.fc8(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331e998-6ead-47e8-88b6-385467b00873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AlexNet(C=3, H=32, W=32, num_classes=10)\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list\n",
    "print('AlexNet: ', sum(numel_list), numel_list)\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(4,3,32,32), device='cpu') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787035c-8378-49c5-a524-9ad14da0b5b9",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e69cb-c4e8-4fe6-b785-c2c1d2c655f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import collections\n",
    "import tqdm\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import datetime\n",
    "current_time = datetime.datetime.today() # 2021-08-15 20:58:43.302125\n",
    "current_time = current_time.strftime('%Y%m%d%H%M%S') # 20210815205827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158ac34-c5e7-4630-81de-b99cbb4bfead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(model, data_loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # y = y.squeeze(1).to(torch.long).to(device)\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = model(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7adff7-48f8-453f-80b1-a4691563f79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "train_losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    n = 0\n",
    "    n_acc = 0\n",
    "    # 시간이 많이 걸리므로 tqdm을 사용해서 진행바를 표시\n",
    "    for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "        # yy = yy.squeeze(1).to(torch.long).to(device)\n",
    "        h = model(xx)\n",
    "        loss = loss_fn(h, yy)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        n += len(xx)\n",
    "        _, y_pred = h.max(1)\n",
    "        n_acc += (yy == y_pred).float().sum().item()\n",
    "    train_losses.append(running_loss / i)\n",
    "    # 훈련 데이터의 예측 정확도\n",
    "    train_acc.append(n_acc / n)\n",
    "\n",
    "    # 검증 데이터의 예측 정확도\n",
    "    val_acc.append(eval_net(model, test_loader, device))\n",
    "    print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush=True)\n",
    "print('-----------training finished-----------')\n",
    "print('train_losses: ', train_losses)\n",
    "print('train_acc: ', train_acc)\n",
    "print('val_acc: ', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54287ebd-aeb7-48db-b800-19dcbf7dc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses)\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c2752b-cff7-40ab-908e-c5943316d0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
